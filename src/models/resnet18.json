{
  "metadata": {
    "name": "resnet18",
    "displayName": "ResNet-18",
    "description": "ResNet-18 是 ResNet 系列中最轻量的变体，包含 18 层网络。使用基本残差块（Basic Block）而非瓶颈结构，适合资源受限场景，同时保留了残差连接的核心优势。此版本为修正后的详细结构，用于精确可视化。",
    "year": 2015,
    "authors": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"],
    "paper": "https://arxiv.org/abs/1512.03385",
    "paperTitle": "Deep Residual Learning for Image Recognition",
    "citations": 293146,
    "tags": ["CNN", "残差网络", "图像分类", "ImageNet"],
    "category": ["CNN"],
    "verified": false
  },
  "layers": [
    {
      "id": "input",
      "name": "输入层",
      "type": "input",
      "description": "网络的入口，接收一批224x224像素的RGB三通道图像。",
      "shape": ["B", 3, 224, 224]
    },
    {
      "id": "conv1",
      "name": "卷积层-1",
      "type": "conv2d",
      "description": "使用7x7的大卷积核进行初步特征提取，并将特征图尺寸减半。",
      "filters": 64,
      "kernelSize": [7, 7],
      "stride": [2, 2],
      "padding": [3, 3],
      "outputShape": ["B", 64, 112, 112]
    },
    {
      "id": "bn1",
      "name": "批归一化层-1",
      "type": "batchnorm",
      "description": "对第一个卷积层的输出进行归一化，以加速模型训练。",
      "outputShape": ["B", 64, 112, 112]
    },
    {
      "id": "relu1",
      "name": "激活函数-1 (ReLU)",
      "type": "relu",
      "description": "对归一化后的数据进行ReLU非线性激活。",
      "outputShape": ["B", 64, 112, 112],
      "activation": "relu"
    },
    {
      "id": "pool1",
      "name": "最大池化层-1",
      "type": "maxpool2d",
      "description": "通过3x3的最大池化操作进一步缩小特征图尺寸。",
      "poolSize": [3, 3],
      "stride": [2, 2],
      "padding": [1, 1],
      "outputShape": ["B", 64, 56, 56]
    },
    {
      "id": "layer1_0_block",
      "name": "并行残差块 Layer1.0",
      "type": "parallel",
      "description": "使用 Parallel 结构封装的残差块 Layer1.0",
      "inputShape": ["B", 64, 56, 56],
      "outputShape": [
        ["B", 64, 56, 56],
        ["B", 64, 56, 56]
      ],
      "branches": [
        {
          "id": "layer1_0_block_main_branch",
          "name": "主分支",
          "steps": [
            {
              "id": "layer1_0_conv1",
              "name": "卷积层-1.0.1",
              "type": "conv2d",
              "description": "残差块1.0的第一个3x3卷积层。",
              "filters": 64,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 64, 56, 56]
            },
            {
              "id": "layer1_0_bn1",
              "name": "批归一化层-1.0.1",
              "type": "batchnorm",
              "description": "对残差块1.0的第一个卷积输出进行归一化处理。",
              "outputShape": ["B", 64, 56, 56]
            },
            {
              "id": "layer1_0_relu1",
              "name": "激活函数-1.0.1 (ReLU)",
              "type": "relu",
              "description": "对数据进行第一次非线性激活。",
              "outputShape": ["B", 64, 56, 56],
              "activation": "relu"
            },
            {
              "id": "layer1_0_conv2",
              "name": "卷积层-1.0.2",
              "type": "conv2d",
              "description": "残差块1.0的第二个3x3卷积层。",
              "filters": 64,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 64, 56, 56]
            },
            {
              "id": "layer1_0_bn2",
              "name": "批归一化层-1.0.2",
              "type": "batchnorm",
              "description": "对残差块1.0的第二个卷积输出进行归一化处理。",
              "outputShape": ["B", 64, 56, 56]
            }
          ],
          "outputShape": ["B", 64, 56, 56]
        },
        {
          "id": "layer1_0_block_skip_branch",
          "name": "捷径分支",
          "steps": [],
          "outputShape": ["B", 64, 56, 56]
        }
      ]
    },
    {
      "id": "layer1_0_add",
      "name": "残差连接-1.0 (相加)",
      "type": "add",
      "description": "将残差块的输入与主路径的输出进行逐元素相加。",
      "outputShape": ["B", 64, 56, 56]
    },
    {
      "id": "layer1_0_relu_out",
      "name": "激活函数-1.0 (输出)",
      "type": "relu",
      "description": "对残差相加后的结果进行最终的ReLU激活。",
      "outputShape": ["B", 64, 56, 56],
      "activation": "relu"
    },
    {
      "id": "layer1_1_block",
      "name": "并行残差块 Layer1.1",
      "type": "parallel",
      "description": "使用 Parallel 结构封装的残差块 Layer1.1",
      "inputShape": ["B", 64, 56, 56],
      "outputShape": [
        ["B", 64, 56, 56],
        ["B", 64, 56, 56]
      ],
      "branches": [
        {
          "id": "layer1_1_block_main_branch",
          "name": "主分支",
          "steps": [
            {
              "id": "layer1_1_conv1",
              "name": "卷积层-1.1.1",
              "type": "conv2d",
              "description": "残差块1.1的第一个3x3卷积层。",
              "filters": 64,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 64, 56, 56]
            },
            {
              "id": "layer1_1_bn1",
              "name": "批归一化层-1.1.1",
              "type": "batchnorm",
              "description": "对残差块1.1的第一个卷积输出进行归一化处理。",
              "outputShape": ["B", 64, 56, 56]
            },
            {
              "id": "layer1_1_relu1",
              "name": "激活函数-1.1.1 (ReLU)",
              "type": "relu",
              "description": "对数据进行第一次非线性激活。",
              "outputShape": ["B", 64, 56, 56],
              "activation": "relu"
            },
            {
              "id": "layer1_1_conv2",
              "name": "卷积层-1.1.2",
              "type": "conv2d",
              "description": "残差块1.1的第二个3x3卷积层。",
              "filters": 64,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 64, 56, 56]
            },
            {
              "id": "layer1_1_bn2",
              "name": "批归一化层-1.1.2",
              "type": "batchnorm",
              "description": "对残差块1.1的第二个卷积输出进行归一化处理。",
              "outputShape": ["B", 64, 56, 56]
            }
          ],
          "outputShape": ["B", 64, 56, 56]
        },
        {
          "id": "layer1_1_block_skip_branch",
          "name": "捷径分支",
          "steps": [],
          "outputShape": ["B", 64, 56, 56]
        }
      ]
    },
    {
      "id": "layer1_1_add",
      "name": "残差连接-1.1 (相加)",
      "type": "add",
      "description": "将残差块的输入与主路径的输出进行逐元素相加。",
      "outputShape": ["B", 64, 56, 56]
    },
    {
      "id": "layer1_1_relu_out",
      "name": "激活函数-1.1 (输出)",
      "type": "relu",
      "description": "对残差相加后的结果进行最终的ReLU激活。",
      "outputShape": ["B", 64, 56, 56],
      "activation": "relu"
    },
    {
      "id": "layer2_0_block",
      "name": "并行残差块 Layer2.0",
      "type": "parallel",
      "description": "使用 Parallel 结构封装的残差块 Layer2.0",
      "inputShape": ["B", 128, 28, 28],
      "outputShape": [
        ["B", 128, 28, 28],
        ["B", 128, 28, 28]
      ],
      "branches": [
        {
          "id": "layer2_0_block_main_branch",
          "name": "主分支",
          "steps": [
            {
              "id": "layer2_0_conv1",
              "name": "卷积层-2.0.1",
              "type": "conv2d",
              "description": "残差块2.0的第一个3x3卷积层，步长为2，进行下采样。",
              "filters": 128,
              "kernelSize": [3, 3],
              "stride": [2, 2],
              "padding": [1, 1],
              "outputShape": ["B", 128, 28, 28]
            },
            {
              "id": "layer2_0_bn1",
              "name": "批归一化层-2.0.1",
              "type": "batchnorm",
              "description": "对残差块2.0的第一个卷积输出进行归一化处理。",
              "outputShape": ["B", 128, 28, 28]
            },
            {
              "id": "layer2_0_relu1",
              "name": "激活函数-2.0.1 (ReLU)",
              "type": "relu",
              "description": "对数据进行第一次非线性激活。",
              "outputShape": ["B", 128, 28, 28],
              "activation": "relu"
            },
            {
              "id": "layer2_0_conv2",
              "name": "卷积层-2.0.2",
              "type": "conv2d",
              "description": "残差块2.0的第二个3x3卷积层。",
              "filters": 128,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 128, 28, 28]
            },
            {
              "id": "layer2_0_bn2",
              "name": "批归一化层-2.0.2",
              "type": "batchnorm",
              "description": "对残差块2.0的第二个卷积输出进行归一化处理。",
              "outputShape": ["B", 128, 28, 28]
            }
          ],
          "outputShape": ["B", 128, 28, 28]
        },
        {
          "id": "layer2_0_block_skip_branch",
          "name": "捷径分支",
          "steps": [
            {
              "id": "layer2_0_downsample_conv",
              "name": "投影卷积层-2.0",
              "type": "conv2d",
              "description": "在残差连接上使用1x1卷积进行下采样和维度匹配。",
              "filters": 128,
              "kernelSize": [1, 1],
              "stride": [2, 2],
              "padding": [0, 0],
              "outputShape": ["B", 128, 28, 28]
            },
            {
              "id": "layer2_0_downsample_bn",
              "name": "投影归一化层-2.0",
              "type": "batchnorm",
              "description": "对投影卷积的输出进行归一化处理。",
              "outputShape": ["B", 128, 28, 28]
            }
          ],
          "outputShape": ["B", 128, 28, 28]
        }
      ]
    },
    {
      "id": "layer2_0_add",
      "name": "残差连接-2.0 (相加)",
      "type": "add",
      "description": "将经过投影的残差连接与主路径的输出进行相加。",
      "outputShape": ["B", 128, 28, 28]
    },
    {
      "id": "layer2_0_relu_out",
      "name": "激活函数-2.0 (输出)",
      "type": "relu",
      "description": "对残差相加后的结果进行最终的ReLU激活。",
      "outputShape": ["B", 128, 28, 28],
      "activation": "relu"
    },
    {
      "id": "layer2_1_block",
      "name": "并行残差块 Layer2.1",
      "type": "parallel",
      "description": "使用 Parallel 结构封装的残差块 Layer2.1",
      "inputShape": ["B", 128, 28, 28],
      "outputShape": [
        ["B", 128, 28, 28],
        ["B", 128, 28, 28]
      ],
      "branches": [
        {
          "id": "layer2_1_block_main_branch",
          "name": "主分支",
          "steps": [
            {
              "id": "layer2_1_conv1",
              "name": "卷积层-2.1.1",
              "type": "conv2d",
              "description": "残差块2.1的第一个3x3卷积层。",
              "filters": 128,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 128, 28, 28]
            },
            {
              "id": "layer2_1_bn1",
              "name": "批归一化层-2.1.1",
              "type": "batchnorm",
              "description": "对残差块2.1的第一个卷积输出进行归一化处理。",
              "outputShape": ["B", 128, 28, 28]
            },
            {
              "id": "layer2_1_relu1",
              "name": "激活函数-2.1.1 (ReLU)",
              "type": "relu",
              "description": "对数据进行第一次非线性激活。",
              "outputShape": ["B", 128, 28, 28],
              "activation": "relu"
            },
            {
              "id": "layer2_1_conv2",
              "name": "卷积层-2.1.2",
              "type": "conv2d",
              "description": "残差块2.1的第二个3x3卷积层。",
              "filters": 128,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 128, 28, 28]
            },
            {
              "id": "layer2_1_bn2",
              "name": "批归一化层-2.1.2",
              "type": "batchnorm",
              "description": "对残差块2.1的第二个卷积输出进行归一化处理。",
              "outputShape": ["B", 128, 28, 28]
            }
          ],
          "outputShape": ["B", 128, 28, 28]
        },
        {
          "id": "layer2_1_block_skip_branch",
          "name": "捷径分支",
          "steps": [],
          "outputShape": ["B", 128, 28, 28]
        }
      ]
    },
    {
      "id": "layer2_1_add",
      "name": "残差连接-2.1 (相加)",
      "type": "add",
      "description": "将残差块的输入与主路径的输出进行逐元素相加。",
      "outputShape": ["B", 128, 28, 28]
    },
    {
      "id": "layer2_1_relu_out",
      "name": "激活函数-2.1 (输出)",
      "type": "relu",
      "description": "对残差相加后的结果进行最终的ReLU激活。",
      "outputShape": ["B", 128, 28, 28],
      "activation": "relu"
    },
    {
      "id": "layer3_0_block",
      "name": "并行残差块 Layer3.0",
      "type": "parallel",
      "description": "使用 Parallel 结构封装的残差块 Layer3.0",
      "inputShape": ["B", "B", 14, 14],
      "outputShape": [
        ["B", "B", 14, 14],
        ["B", "B", 14, 14]
      ],
      "branches": [
        {
          "id": "layer3_0_block_main_branch",
          "name": "主分支",
          "steps": [
            {
              "id": "layer3_0_conv1",
              "name": "卷积层-3.0.1",
              "type": "conv2d",
              "description": "残差块3.0的第一个3x3卷积层，步长为2，进行下采样。",
              "filters": "B",
              "kernelSize": [3, 3],
              "stride": [2, 2],
              "padding": [1, 1],
              "outputShape": ["B", "B", 14, 14]
            },
            {
              "id": "layer3_0_bn1",
              "name": "批归一化层-3.0.1",
              "type": "batchnorm",
              "description": "对残差块3.0的第一个卷积输出进行归一化处理。",
              "outputShape": ["B", "B", 14, 14]
            },
            {
              "id": "layer3_0_relu1",
              "name": "激活函数-3.0.1 (ReLU)",
              "type": "relu",
              "description": "对数据进行第一次非线性激活。",
              "outputShape": ["B", "B", 14, 14],
              "activation": "relu"
            },
            {
              "id": "layer3_0_conv2",
              "name": "卷积层-3.0.2",
              "type": "conv2d",
              "description": "残差块3.0的第二个3x3卷积层。",
              "filters": "B",
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", "B", 14, 14]
            },
            {
              "id": "layer3_0_bn2",
              "name": "批归一化层-3.0.2",
              "type": "batchnorm",
              "description": "对残差块3.0的第二个卷积输出进行归一化处理。",
              "outputShape": ["B", "B", 14, 14]
            }
          ],
          "outputShape": ["B", "B", 14, 14]
        },
        {
          "id": "layer3_0_block_skip_branch",
          "name": "捷径分支",
          "steps": [
            {
              "id": "layer3_0_downsample_conv",
              "name": "投影卷积层-3.0",
              "type": "conv2d",
              "description": "在残差连接上使用1x1卷积进行下采样和维度匹配。",
              "filters": "B",
              "kernelSize": [1, 1],
              "stride": [2, 2],
              "padding": [0, 0],
              "outputShape": ["B", "B", 14, 14]
            },
            {
              "id": "layer3_0_downsample_bn",
              "name": "投影归一化层-3.0",
              "type": "batchnorm",
              "description": "对投影卷积的输出进行归一化处理。",
              "outputShape": ["B", "B", 14, 14]
            }
          ],
          "outputShape": ["B", "B", 14, 14]
        }
      ]
    },
    {
      "id": "layer3_0_add",
      "name": "残差连接-3.0 (相加)",
      "type": "add",
      "description": "将经过投影的残差连接与主路径的输出进行相加。",
      "outputShape": ["B", "B", 14, 14]
    },
    {
      "id": "layer3_0_relu_out",
      "name": "激活函数-3.0 (输出)",
      "type": "relu",
      "description": "对残差相加后的结果进行最终的ReLU激活。",
      "outputShape": ["B", "B", 14, 14],
      "activation": "relu"
    },
    {
      "id": "layer3_1_block",
      "name": "并行残差块 Layer3.1",
      "type": "parallel",
      "description": "使用 Parallel 结构封装的残差块 Layer3.1",
      "inputShape": ["B", "B", 14, 14],
      "outputShape": [
        ["B", "B", 14, 14],
        ["B", "B", 14, 14]
      ],
      "branches": [
        {
          "id": "layer3_1_block_main_branch",
          "name": "主分支",
          "steps": [
            {
              "id": "layer3_1_conv1",
              "name": "卷积层-3.1.1",
              "type": "conv2d",
              "description": "残差块3.1的第一个3x3卷积层。",
              "filters": "B",
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", "B", 14, 14]
            },
            {
              "id": "layer3_1_bn1",
              "name": "批归一化层-3.1.1",
              "type": "batchnorm",
              "description": "对残差块3.1的第一个卷积输出进行归一化处理。",
              "outputShape": ["B", "B", 14, 14]
            },
            {
              "id": "layer3_1_relu1",
              "name": "激活函数-3.1.1 (ReLU)",
              "type": "relu",
              "description": "对数据进行第一次非线性激活。",
              "outputShape": ["B", "B", 14, 14],
              "activation": "relu"
            },
            {
              "id": "layer3_1_conv2",
              "name": "卷积层-3.1.2",
              "type": "conv2d",
              "description": "残差块3.1的第二个3x3卷积层。",
              "filters": "B",
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", "B", 14, 14]
            },
            {
              "id": "layer3_1_bn2",
              "name": "批归一化层-3.1.2",
              "type": "batchnorm",
              "description": "对残差块3.1的第二个卷积输出进行归一化处理。",
              "outputShape": ["B", "B", 14, 14]
            }
          ],
          "outputShape": ["B", "B", 14, 14]
        },
        {
          "id": "layer3_1_block_skip_branch",
          "name": "捷径分支",
          "steps": [],
          "outputShape": ["B", "B", 14, 14]
        }
      ]
    },
    {
      "id": "layer3_1_add",
      "name": "残差连接-3.1 (相加)",
      "type": "add",
      "description": "将残差块的输入与主路径的输出进行逐元素相加。",
      "outputShape": ["B", "B", 14, 14]
    },
    {
      "id": "layer3_1_relu_out",
      "name": "激活函数-3.1 (输出)",
      "type": "relu",
      "description": "对残差相加后的结果进行最终的ReLU激活。",
      "outputShape": ["B", "B", 14, 14],
      "activation": "relu"
    },
    {
      "id": "layer4_0_block",
      "name": "并行残差块 Layer4.0",
      "type": "parallel",
      "description": "使用 Parallel 结构封装的残差块 Layer4.0",
      "inputShape": ["B", 512, 7, 7],
      "outputShape": [
        ["B", 512, 7, 7],
        ["B", 512, 7, 7]
      ],
      "branches": [
        {
          "id": "layer4_0_block_main_branch",
          "name": "主分支",
          "steps": [
            {
              "id": "layer4_0_conv1",
              "name": "卷积层-4.0.1",
              "type": "conv2d",
              "description": "残差块4.0的第一个3x3卷积层，步长为2，进行下采样。",
              "filters": 512,
              "kernelSize": [3, 3],
              "stride": [2, 2],
              "padding": [1, 1],
              "outputShape": ["B", 512, 7, 7]
            },
            {
              "id": "layer4_0_bn1",
              "name": "批归一化层-4.0.1",
              "type": "batchnorm",
              "description": "对残差块4.0的第一个卷积输出进行归一化处理。",
              "outputShape": ["B", 512, 7, 7]
            },
            {
              "id": "layer4_0_relu1",
              "name": "激活函数-4.0.1 (ReLU)",
              "type": "relu",
              "description": "对数据进行第一次非线性激活。",
              "outputShape": ["B", 512, 7, 7],
              "activation": "relu"
            },
            {
              "id": "layer4_0_conv2",
              "name": "卷积层-4.0.2",
              "type": "conv2d",
              "description": "残差块4.0的第二个3x3卷积层。",
              "filters": 512,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 512, 7, 7]
            },
            {
              "id": "layer4_0_bn2",
              "name": "批归一化层-4.0.2",
              "type": "batchnorm",
              "description": "对残差块4.0的第二个卷积输出进行归一化处理。",
              "outputShape": ["B", 512, 7, 7]
            }
          ],
          "outputShape": ["B", 512, 7, 7]
        },
        {
          "id": "layer4_0_block_skip_branch",
          "name": "捷径分支",
          "steps": [
            {
              "id": "layer4_0_downsample_conv",
              "name": "投影卷积层-4.0",
              "type": "conv2d",
              "description": "在残差连接上使用1x1卷积进行下采样和维度匹配。",
              "filters": 512,
              "kernelSize": [1, 1],
              "stride": [2, 2],
              "padding": [0, 0],
              "outputShape": ["B", 512, 7, 7]
            },
            {
              "id": "layer4_0_downsample_bn",
              "name": "投影归一化层-4.0",
              "type": "batchnorm",
              "description": "对投影卷积的输出进行归一化处理。",
              "outputShape": ["B", 512, 7, 7]
            }
          ],
          "outputShape": ["B", 512, 7, 7]
        }
      ]
    },
    {
      "id": "layer4_0_add",
      "name": "残差连接-4.0 (相加)",
      "type": "add",
      "description": "将经过投影的残差连接与主路径的输出进行相加。",
      "outputShape": ["B", 512, 7, 7]
    },
    {
      "id": "layer4_0_relu_out",
      "name": "激活函数-4.0 (输出)",
      "type": "relu",
      "description": "对残差相加后的结果进行最终的ReLU激活。",
      "outputShape": ["B", 512, 7, 7],
      "activation": "relu"
    },
    {
      "id": "layer4_1_block",
      "name": "并行残差块 Layer4.1",
      "type": "parallel",
      "description": "使用 Parallel 结构封装的残差块 Layer4.1",
      "inputShape": ["B", 512, 7, 7],
      "outputShape": [
        ["B", 512, 7, 7],
        ["B", 512, 7, 7]
      ],
      "branches": [
        {
          "id": "layer4_1_block_main_branch",
          "name": "主分支",
          "steps": [
            {
              "id": "layer4_1_conv1",
              "name": "卷积层-4.1.1",
              "type": "conv2d",
              "description": "残差块4.1的第一个3x3卷积层。",
              "filters": 512,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 512, 7, 7]
            },
            {
              "id": "layer4_1_bn1",
              "name": "批归一化层-4.1.1",
              "type": "batchnorm",
              "description": "对残差块4.1的第一个卷积输出进行归一化处理。",
              "outputShape": ["B", 512, 7, 7]
            },
            {
              "id": "layer4_1_relu1",
              "name": "激活函数-4.1.1 (ReLU)",
              "type": "relu",
              "description": "对数据进行第一次非线性激活。",
              "outputShape": ["B", 512, 7, 7],
              "activation": "relu"
            },
            {
              "id": "layer4_1_conv2",
              "name": "卷积层-4.1.2",
              "type": "conv2d",
              "description": "残差块4.1的第二个3x3卷积层。",
              "filters": 512,
              "kernelSize": [3, 3],
              "stride": [1, 1],
              "padding": [1, 1],
              "outputShape": ["B", 512, 7, 7]
            },
            {
              "id": "layer4_1_bn2",
              "name": "批归一化层-4.1.2",
              "type": "batchnorm",
              "description": "对残差块4.1的第二个卷积输出进行归一化处理。",
              "outputShape": ["B", 512, 7, 7]
            }
          ],
          "outputShape": ["B", 512, 7, 7]
        },
        {
          "id": "layer4_1_block_skip_branch",
          "name": "捷径分支",
          "steps": [],
          "outputShape": ["B", 512, 7, 7]
        }
      ]
    },
    {
      "id": "layer4_1_add",
      "name": "残差连接-4.1 (相加)",
      "type": "add",
      "description": "将残差块的输入与主路径的输出进行逐元素相加。",
      "outputShape": ["B", 512, 7, 7]
    },
    {
      "id": "layer4_1_relu_out",
      "name": "激活函数-4.1 (输出)",
      "type": "relu",
      "description": "对残差相加后的结果进行最终的ReLU激活。",
      "outputShape": ["B", 512, 7, 7],
      "activation": "relu"
    },
    {
      "id": "avgpool",
      "name": "全局平均池化层",
      "type": "adaptiveavgpool2d",
      "description": "将每个特征图缩减为一个单一数值，得到一个512维的特征向量。",
      "outputShape": ["B", 512, 1, 1]
    },
    {
      "id": "flatten",
      "name": "展平层",
      "type": "flatten",
      "description": "移除多余的维度以便将数据输入到全连接层。",
      "outputShape": ["B", 512]
    },
    {
      "id": "fc",
      "name": "全连接层",
      "type": "linear",
      "description": "将512维特征映射到1000个分类类别上。",
      "units": 1000,
      "outputShape": ["B", 1000]
    },
    {
      "id": "output",
      "name": "输出层",
      "type": "linear",
      "description": "通过Softmax函数计算最终每个类别的预测概率。",
      "outputShape": ["B", 1000]
    },
    {
      "id": "output_act",
      "name": "Softmax 激活",
      "type": "softmax",
      "activation": "softmax",
      "inputShape": ["B", 1000],
      "outputShape": ["B", 1000]
    }
  ],
  "edges": [
    {
      "id": "edge_0_input_to_conv1_normal",
      "source": "input",
      "target": "conv1",
      "type": "normal"
    },
    {
      "id": "edge_1_conv1_to_bn1_normal",
      "source": "conv1",
      "target": "bn1",
      "type": "normal"
    },
    {
      "id": "edge_2_bn1_to_relu1_normal",
      "source": "bn1",
      "target": "relu1",
      "type": "normal"
    },
    {
      "id": "edge_3_relu1_to_pool1_normal",
      "source": "relu1",
      "target": "pool1",
      "type": "normal"
    },
    {
      "id": "edge_4_pool1_to_layer1_0_block_normal",
      "source": "pool1",
      "target": "layer1_0_block",
      "type": "normal"
    },
    {
      "id": "edge_5_layer1_0_block_to_layer1_0_add_normal",
      "source": "layer1_0_block",
      "target": "layer1_0_add",
      "type": "normal"
    },
    {
      "id": "edge_6_layer1_0_block_to_layer1_0_add_residual",
      "source": "layer1_0_block",
      "target": "layer1_0_add",
      "type": "normal"
    },
    {
      "id": "edge_7_layer1_0_add_to_layer1_0_relu_out_normal",
      "source": "layer1_0_add",
      "target": "layer1_0_relu_out",
      "type": "normal"
    },
    {
      "id": "edge_8_layer1_0_relu_out_to_layer1_1_block_normal",
      "source": "layer1_0_relu_out",
      "target": "layer1_1_block",
      "type": "normal"
    },
    {
      "id": "edge_9_layer1_1_block_to_layer1_1_add_normal",
      "source": "layer1_1_block",
      "target": "layer1_1_add",
      "type": "normal"
    },
    {
      "id": "edge_10_layer1_1_block_to_layer1_1_add_residual",
      "source": "layer1_1_block",
      "target": "layer1_1_add",
      "type": "normal"
    },
    {
      "id": "edge_11_layer1_1_add_to_layer1_1_relu_out_normal",
      "source": "layer1_1_add",
      "target": "layer1_1_relu_out",
      "type": "normal"
    },
    {
      "id": "edge_12_layer1_1_relu_out_to_layer2_0_block_normal",
      "source": "layer1_1_relu_out",
      "target": "layer2_0_block",
      "type": "normal"
    },
    {
      "id": "edge_13_layer2_0_block_to_layer2_0_add_normal",
      "source": "layer2_0_block",
      "target": "layer2_0_add",
      "type": "normal"
    },
    {
      "id": "edge_14_layer2_0_block_to_layer2_0_add_residual",
      "source": "layer2_0_block",
      "target": "layer2_0_add",
      "type": "normal"
    },
    {
      "id": "edge_15_layer2_0_add_to_layer2_0_relu_out_normal",
      "source": "layer2_0_add",
      "target": "layer2_0_relu_out",
      "type": "normal"
    },
    {
      "id": "edge_16_layer2_0_relu_out_to_layer2_1_block_normal",
      "source": "layer2_0_relu_out",
      "target": "layer2_1_block",
      "type": "normal"
    },
    {
      "id": "edge_17_layer2_1_block_to_layer2_1_add_normal",
      "source": "layer2_1_block",
      "target": "layer2_1_add",
      "type": "normal"
    },
    {
      "id": "edge_18_layer2_1_block_to_layer2_1_add_residual",
      "source": "layer2_1_block",
      "target": "layer2_1_add",
      "type": "normal"
    },
    {
      "id": "edge_19_layer2_1_add_to_layer2_1_relu_out_normal",
      "source": "layer2_1_add",
      "target": "layer2_1_relu_out",
      "type": "normal"
    },
    {
      "id": "edge_20_layer2_1_relu_out_to_layer3_0_block_normal",
      "source": "layer2_1_relu_out",
      "target": "layer3_0_block",
      "type": "normal"
    },
    {
      "id": "edge_21_layer3_0_block_to_layer3_0_add_normal",
      "source": "layer3_0_block",
      "target": "layer3_0_add",
      "type": "normal"
    },
    {
      "id": "edge_22_layer3_0_block_to_layer3_0_add_residual",
      "source": "layer3_0_block",
      "target": "layer3_0_add",
      "type": "normal"
    },
    {
      "id": "edge_23_layer3_0_add_to_layer3_0_relu_out_normal",
      "source": "layer3_0_add",
      "target": "layer3_0_relu_out",
      "type": "normal"
    },
    {
      "id": "edge_24_layer3_0_relu_out_to_layer3_1_block_normal",
      "source": "layer3_0_relu_out",
      "target": "layer3_1_block",
      "type": "normal"
    },
    {
      "id": "edge_25_layer3_1_block_to_layer3_1_add_normal",
      "source": "layer3_1_block",
      "target": "layer3_1_add",
      "type": "normal"
    },
    {
      "id": "edge_26_layer3_1_block_to_layer3_1_add_residual",
      "source": "layer3_1_block",
      "target": "layer3_1_add",
      "type": "normal"
    },
    {
      "id": "edge_27_layer3_1_add_to_layer3_1_relu_out_normal",
      "source": "layer3_1_add",
      "target": "layer3_1_relu_out",
      "type": "normal"
    },
    {
      "id": "edge_28_layer3_1_relu_out_to_layer4_0_block_normal",
      "source": "layer3_1_relu_out",
      "target": "layer4_0_block",
      "type": "normal"
    },
    {
      "id": "edge_29_layer4_0_block_to_layer4_0_add_normal",
      "source": "layer4_0_block",
      "target": "layer4_0_add",
      "type": "normal"
    },
    {
      "id": "edge_30_layer4_0_block_to_layer4_0_add_residual",
      "source": "layer4_0_block",
      "target": "layer4_0_add",
      "type": "normal"
    },
    {
      "id": "edge_31_layer4_0_add_to_layer4_0_relu_out_normal",
      "source": "layer4_0_add",
      "target": "layer4_0_relu_out",
      "type": "normal"
    },
    {
      "id": "edge_32_layer4_0_relu_out_to_layer4_1_block_normal",
      "source": "layer4_0_relu_out",
      "target": "layer4_1_block",
      "type": "normal"
    },
    {
      "id": "edge_33_layer4_1_block_to_layer4_1_add_normal",
      "source": "layer4_1_block",
      "target": "layer4_1_add",
      "type": "normal"
    },
    {
      "id": "edge_34_layer4_1_block_to_layer4_1_add_residual",
      "source": "layer4_1_block",
      "target": "layer4_1_add",
      "type": "normal"
    },
    {
      "id": "edge_35_layer4_1_add_to_layer4_1_relu_out_normal",
      "source": "layer4_1_add",
      "target": "layer4_1_relu_out",
      "type": "normal"
    },
    {
      "id": "edge_36_layer4_1_relu_out_to_avgpool_normal",
      "source": "layer4_1_relu_out",
      "target": "avgpool",
      "type": "normal"
    },
    {
      "id": "edge_37_avgpool_to_flatten_normal",
      "source": "avgpool",
      "target": "flatten",
      "type": "normal"
    },
    {
      "id": "edge_38_flatten_to_fc_normal",
      "source": "flatten",
      "target": "fc",
      "type": "normal"
    },
    {
      "id": "edge_39_fc_to_output_normal",
      "source": "fc",
      "target": "output",
      "type": "normal"
    },
    {
      "id": "edge_40_output_to_output_act_normal",
      "source": "output",
      "target": "output_act",
      "type": "normal"
    }
  ]
}
